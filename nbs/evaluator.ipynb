{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluator Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.3) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import CodeCheckList.utils as utils\n",
    "from CodeCheckList.tokenizer import CodeTokenizer\n",
    "from CodeCheckList.masker import Masker\n",
    "from CodeCheckList.predictor import Predictor\n",
    "from CodeCheckList.judge import Judge\n",
    "\n",
    "import statistics\n",
    "import textdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Evaluator:\n",
    "    \"\"\"Evaluator Module to perform all AST Evaluations\"\"\"\n",
    "    def __init__(self, checkpoint: str, language, gpu_available=False, save_path: str = None):\n",
    "        os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "        self.tokenizer = CodeTokenizer.from_pretrained(checkpoint, language)\n",
    "        self.masker = Masker(self.tokenizer)\n",
    "        self.predictor = Predictor.from_pretrained(checkpoint, self.tokenizer, gpu_available)\n",
    "        self.judge = Judge(self.tokenizer)\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def __call__(self, test_set, concepts: list, masking_rate: float, code_field: str, random_sampling: int):\n",
    "        result_list = self.evaluate_concepts_in_test_set(concepts, test_set, masking_rate, code_field, random_sampling)\n",
    "        return self.save_checkpoint(result_list)\n",
    "    \n",
    "    def save_checkpoint(self, result_list: list):\n",
    "        results_dataframe = pd.DataFrame([], columns=[\n",
    "            'sample_id', 'ast_element', 'sample', 'masking_rate', 'numper_of_masked_tokens',\n",
    "            'ast_element_ocurrences','mask_jaccard', 'mask_sorensen_dice', 'mask_levenshtein', \n",
    "            'mask_random_avg_jaccard', 'mask_random_avg_sorensen_dice', 'mask_random_avg_levenshtein',\n",
    "            'mask_random_std_jaccard', 'mask_random_std_sorensen_dice', 'mask_random_std_levenshtein',\n",
    "            'n_ast_errors', 'ast_levels', 'n_whitespaces_', 'complexity', 'nloc', 'token_counts', 'n_ast_nodes' #CONFOUNDERS\n",
    "            ])\n",
    "        for result_index, result in enumerate(result_list):\n",
    "            results_dataframe.loc[len(results_dataframe.index)] = result\n",
    "        if self.save_path != None:\n",
    "            results_dataframe.to_csv(self.save_path)\n",
    "        return results_dataframe\n",
    "\n",
    "    \n",
    "    def pipeline(self, test_set, number_of_predictions: int, masking_rate: float):\n",
    "        \"\"\"Deprecated\"\"\"\n",
    "        results_dict = self.evaluate_test_set(test_set, number_of_predictions, masking_rate)\n",
    "        results_dataframe = pd.DataFrame([], columns=[\n",
    "            'ast_element', 'occurences', 'jaccard', 'sorensen_dice', 'levenshtein', 'jaccard_avg', 'sorensen_dice_avg', 'levenshtein_avg'])\n",
    "        for result_index, result in enumerate(results_dict):\n",
    "            results_dataframe.loc[len(results_dataframe.index)] = [self.tokenizer.node_types[result_index], result[0], tuple(tuple(l) for l in result[1]), tuple(tuple(l) for l in result[2]), tuple(tuple(l) for l in result[3]), tuple(result[4]), tuple(result[5]), tuple(result[6])]\n",
    "        return results_dataframe\n",
    "    \n",
    "    def evaluate_test_set(self, test_set, number_of_predictions: int, masking_rate: float):\n",
    "        \"\"\"Deprecated\"\"\"\n",
    "        results_dict = []\n",
    "        for node_type in self.tokenizer.node_types:\n",
    "            results_dict.append([0,                                           #ocurrences\n",
    "                                [[] for i in range(0,number_of_predictions)], #jaccard per prediction\n",
    "                                [[] for i in range(0,number_of_predictions)], #sorensen_dice per prediction\n",
    "                                [[] for i in range(0,number_of_predictions)], #levenshtein per prediction\n",
    "                                [0 for i in range(0,number_of_predictions)],  #avg jaccard per prediction\n",
    "                                [0 for i in range(0,number_of_predictions)],  #avg sorensen_dice per prediction\n",
    "                                [0 for i in range(0,number_of_predictions)],  #avg levenshtein per prediction\n",
    "                                ])\n",
    "        for sample_index, sample in enumerate(test_set):\n",
    "            print('-------- evaluating sample:'+str(sample_index)+' --------')\n",
    "            for node_type_idx, node_type in enumerate(self.tokenizer.node_types):\n",
    "                node_type_results = self.evaluate_node_type_on_snippet(sample['whole_func_string'], node_type_idx, number_of_predictions, masking_rate)\n",
    "                if(len(node_type_results)>0):\n",
    "                    results_dict[node_type_idx][0] += node_type_results[0][0]\n",
    "                    for prediction_number_index in range(0, number_of_predictions):\n",
    "                        if(node_type_results[prediction_number_index][1]!=None):\n",
    "                            results_dict[node_type_idx][1][prediction_number_index].append(node_type_results[prediction_number_index][1])\n",
    "                            results_dict[node_type_idx][4][prediction_number_index] = round(statistics.mean(results_dict[node_type_idx][1][prediction_number_index]),3)\n",
    "                        if(node_type_results[prediction_number_index][2]!=None):\n",
    "                            results_dict[node_type_idx][2][prediction_number_index].append(node_type_results[prediction_number_index][2])\n",
    "                            results_dict[node_type_idx][5][prediction_number_index] = round(statistics.mean(results_dict[node_type_idx][2][prediction_number_index]),3)\n",
    "                        if(node_type_results[prediction_number_index][3]!=None):\n",
    "                            results_dict[node_type_idx][3][prediction_number_index].append(node_type_results[prediction_number_index][3])\n",
    "                            results_dict[node_type_idx][6][prediction_number_index] = round(statistics.mean(results_dict[node_type_idx][3][prediction_number_index]),3)\n",
    "        return results_dict\n",
    "        \n",
    "    def evaluate_node_type_on_snippet(self, source_code: str, target_node_type_idx: int, number_of_predictions: int, masking_rate: float):\n",
    "        results=[]\n",
    "        source_code_tree = self.tokenizer.parser.parse(bytes(source_code, \"utf8\"))\n",
    "        source_code_nodes = []\n",
    "        utils.find_nodes(source_code_tree.root_node, self.tokenizer.node_types[target_node_type_idx], source_code_nodes)\n",
    "        if len(source_code_nodes) == 0:\n",
    "            return results, 0\n",
    "        masked_code_encoding, number_of_masked_tokens = self.masker.mask_ast_tokens(source_code, self.tokenizer(source_code), target_node_type_idx, masking_rate)\n",
    "        if number_of_masked_tokens == 0: #Not masking anything\n",
    "            return results, 0\n",
    "        predictions = self.predictor(masked_code_encoding, self.tokenizer.tokenizer(source_code, return_tensors='pt'), number_of_predictions)  \n",
    "        for prediction_number in range(0, number_of_predictions):\n",
    "            predicted_code = predictions[prediction_number]\n",
    "            prediction_results = self.judge(source_code, predicted_code)\n",
    "            results.append([len(source_code_nodes), prediction_results[0], prediction_results[1], prediction_results[2]])\n",
    "        return results, number_of_masked_tokens\n",
    "    \n",
    "    def evaluate_random_mask_on_snippet(self, source_code: str, number_of_predictions:int, number_tokens_to_mask: int):\n",
    "        results=[]\n",
    "        masked_code_encoding = self.masker.mask_random_tokens(self.tokenizer(source_code), number_tokens_to_mask)\n",
    "        predictions = self.predictor(masked_code_encoding, self.tokenizer.tokenizer(source_code, return_tensors='pt'), number_of_predictions)\n",
    "        for prediction_number in range(0, number_of_predictions):\n",
    "            predicted_code = predictions[prediction_number]\n",
    "            prediction_results = self.judge(source_code, predicted_code)\n",
    "            results.append([0, prediction_results[0], prediction_results[1], prediction_results[2]])\n",
    "        return results\n",
    "    \n",
    "    def evaluate_concepts_in_test_set(self, concepts: list, test_set, masking_rate: float, code_field: str, random_sampling: int):\n",
    "        test_set_results = []\n",
    "        for sample_index, sample in enumerate(test_set):\n",
    "            print('-------- evaluating sample:'+str(sample_index)+' --------')\n",
    "            for concept in concepts: \n",
    "                concept_mask_results, number_of_masked_tokens = self.evaluate_node_type_on_snippet(sample[code_field], self.tokenizer.node_types.index(concept), 1, masking_rate)\n",
    "                \n",
    "                random_mask_results = [[],[],[]]\n",
    "                for idx in range(0, random_sampling):\n",
    "                    random_mask_result = self.evaluate_random_mask_on_snippet(sample[code_field], 1, number_of_masked_tokens)\n",
    "                    random_mask_results[0].append(random_mask_result[0][1])\n",
    "                    random_mask_results[1].append(random_mask_result[0][2])\n",
    "                    random_mask_results[2].append(random_mask_result[0][3])\n",
    "\n",
    "                if len(concept_mask_results)>0:\n",
    "                    'n_ast_errors', 'ast_levels', 'n_whitespaces_', 'complexity', 'nloc', 'token_counts', 'n_ast_nodes'\n",
    "                    test_set_results.append([sample_index, concept, sample[code_field], masking_rate, number_of_masked_tokens,\n",
    "                                            concept_mask_results[0][0], concept_mask_results[0][1], concept_mask_results[0][2], concept_mask_results[0][3], \n",
    "                                            statistics.mean(random_mask_results[0]), statistics.mean(random_mask_results[1]), statistics.mean(random_mask_results[2]),\n",
    "                                            statistics.stdev(random_mask_results[0]), statistics.stdev(random_mask_results[1]), statistics.stdev(random_mask_results[2]),\n",
    "                                            sample['n_ast_errors'], sample['ast_levels'], sample['n_whitespaces_'], sample['complexity'], sample['nloc'], sample['token_counts'], sample['n_ast_nodes'] #CONFOUNDERS\n",
    "                                            ])\n",
    "                    if sample_index % 100 == 0: \n",
    "                        self.save_checkpoint(test_set_results)\n",
    "        self.save_checkpoint(test_set_results)\n",
    "        return test_set_results\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/CodeCheckList/grammars\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "from CodeCheckList import loader\n",
    "\n",
    "\"\"\"define language\"\"\"\n",
    "python_language = \"python\"\n",
    "\n",
    "languages = [python_language]\n",
    "\n",
    "loader.download_grammars(languages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "\"\"\"define the model checkpoint\"\"\"\n",
    "checkpoint = \"huggingface/CodeBERTa-small-v1\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "from CodeCheckList.tokenizer import CodeTokenizer\n",
    "from CodeCheckList.masker import Masker\n",
    "\n",
    "#create code tokenizer \n",
    "bert_tokenizer = CodeTokenizer.from_pretrained(checkpoint, python_language)\n",
    "\n",
    "#create code masker\n",
    "code_masker = Masker(bert_tokenizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['expression_statement', 'primary_expression', 'aliased_import', 'list_comprehension', 'type', 'dictionary_comprehension', 'named_expression', 'pass', 'ERROR', 'relative_import', '{{', 'string', 'except', 'false', 'none', 'parenthesized_expression', '}}', '(', 'assert', 'attribute', 'positional_separator', 'import_prefix', ':=', '>', '|', 'concatenated_string', 'format_expression', 'set_comprehension', 'import_from_statement', 'binary_operator', 'interpolation', 'if_statement', 'lambda', 'case_pattern', '->', 'call', '-=', 'future_import_statement', '+=', '**', '<>', '[', 'tuple', 'class', 'list', 'delete_statement', 'decorator', 'with_clause', 'with_item', 'typed_default_parameter', 'def', '=', 'break', 'elif', 'argument_list', 'format_specifier', 'case_clause', 'continue_statement', 'exec_statement', ')', 'case', 'global', 'assignment', 'import', '%', '//=', 'continue', '|=', 'typed_parameter', 'keyword_argument', '&=', '\"', ']', 'elif_clause', 'class_definition', 'while', 'with', '>>=', 'list_pattern', 'block', 'await', 'with_statement', '<=', 'assert_statement', 'or', 'del', 'comment', 'return', 'print_statement', 'true', 'if', '+', 'import_statement', 'comparison_operator', 'tuple_pattern', 'as', 'boolean_operator', 'float', 'while_statement', 'slice', 'lambda_parameters', 'print', 'finally_clause', 'break_statement', 'for_statement', '**=', 'parenthesized_list_splat', '__future__', 'subscript', 'parameter', 'else_clause', 'raise_statement', 'dictionary', 'as_pattern', 'parameters', 'type_conversion', ':', 'for_in_clause', 'integer', 'augmented_assignment', '&', 'dotted_name', 'pair', '//', 'and', 'chevron', '~', '*=', 'raise', 'global_statement', '^', 'except_clause', '<<=', 'is', 'set', 'generator_expression', '^=', 'if_clause', '<', 'finally', 'from', '}', 'decorated_definition', '<<', 'function_definition', 'expression', 'escape_sequence', 'pattern', 'dictionary_splat', 'ellipsis', 'module', 'default_parameter', '/', 'keyword_separator', 'identifier', 'pattern_list', 'not', '@', '@=', '>=', 'match', 'exec', ';', 'nonlocal_statement', ',', 'match_statement', '_simple_statement', 'try', 'for', '_compound_statement', 'dictionary_splat_pattern', '{', 'list_splat', 'try_statement', 'yield', 'async', '%=', '-', 'expression_list', 'list_splat_pattern', '/=', 'as_pattern_target', 'nonlocal', 'pass_statement', 'return_statement', '*', '>>', '!=', 'not_operator', '.', 'else', 'unary_operator', 'conditional_expression', 'in', '==', 'wildcard_import']\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "print(bert_tokenizer.node_types)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def<mask><mask><mask>(<mask>,<mask>):\n",
      "    return<mask>*<mask>\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "\"\"\"example source code\"\"\"\n",
    "\n",
    "code = \"def multiply_numbers(a,b):\\n    return a*b\"\n",
    "#code = \"def scale(self, center=True, scale=True):\\n        \\\"\\\"\\\"\\nthe the\\n\\n\\n                                                                                                                                                          _\\n                     ____________=_=_===========________===______________________________==_____________________\\n_______\\n____\\n\\n___\\n\\n\\n\\n\\n\\n\\n\\n\\n        return return)\"\n",
    "#code = \"def hello_world(a,b):\\n    print('hello world')\"\n",
    "#code = \"def __ordered_values_by_indexes(self, data, inds): \\\"\\\"\\\" Return values (intensities) by indexes. Used for multiscale graph cut. data = [[0 1 1], [0 2 2], [0 2 2]] inds = [[0 1 2], [3 4 4], [5 4 4]] return: [0, 1, 1, 0, 2, 0] If the data are not consistent, it will take the maximal value \\\"\\\"\\\" # get unique labels and their first indexes # lab, linds = np.unique(inds, return_index=True) # compute values by indexes # values = data.reshape(-1)[linds] # alternative slow implementation # if there are different data on same index, it will take # maximal value # lab = np.unique(inds) # values = [0]*len(lab) # for label in lab: # values[label] = np.max(data[inds == label]) # # values = np.asarray(values) # yet another implementation values = [None] * (np.max(inds) + 1) linear_inds = inds.ravel() linear_data = data.ravel() for i in range(0, len(linear_inds)): # going over all data pixels if values[linear_inds[i]] is None: # this index is found for first values[linear_inds[i]] = linear_data[i] elif values[linear_inds[i]] < linear_data[i]: # here can be changed maximal or minimal value values[linear_inds[i]] = linear_data[i] values = np.asarray(values) return values\"\n",
    "#code = \"def __ordered_values_by_indexes(self, data, inds):  # get unique labels and their first indexes # lab, linds = np.unique(inds, return_index=True) # compute values by indexes # values = data.reshape(-1)[linds] # alternative slow implementation # if there are different data on same index, it will take # maximal value # lab = np.unique(inds) # values = [0]*len(lab) # for label in lab: # values[label] = np.max(data[inds == label]) # # values = np.asarray(values) # yet another implementation values = [None] * (np.max(inds) + 1) linear_inds = inds.ravel() linear_data = data.ravel() for i in range(0, len(linear_inds)): # going over all data pixels if values[linear_inds[i]] is None: # this index is found for first values[linear_inds[i]] = linear_data[i] elif values[linear_inds[i]] < linear_data[i]: # here can be changed maximal or minimal value values[linear_inds[i]] = linear_data[i] values = np.asarray(values) return values\"\n",
    "target_node_type = \"identifier\"\n",
    "\n",
    "#encoding \n",
    "source_code_encoding = bert_tokenizer(code)\n",
    "\n",
    "#masking\n",
    "masked_code_encoding, number_of_masked_tokens = code_masker.mask_ast_tokens(code, bert_tokenizer(code), bert_tokenizer.node_types.index(target_node_type), 1)\n",
    "\n",
    "assert len(source_code_encoding['input_ids']) == len(masked_code_encoding['input_ids'])\n",
    "\n",
    "#masked code\n",
    "masked_code = bert_tokenizer.tokenizer.decode(list(filter(lambda token_id: False if token_id == bert_tokenizer.tokenizer.bos_token_id or \n",
    "            token_id == bert_tokenizer.tokenizer.eos_token_id else True, masked_code_encoding['input_ids'])))\n",
    "\n",
    "print(masked_code)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "from CodeCheckList.predictor import Predictor\n",
    "\n",
    "predictor = Predictor.from_pretrained(checkpoint, bert_tokenizer)\n",
    "predictions = predictor(masked_code_encoding, bert_tokenizer.tokenizer(code, return_tensors='pt'), 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- CODE -------------\n",
      "def multiply_numbers(a,b):\n",
      "    return a*b\n",
      "\n",
      "---------- MASKED -------------\n",
      "def<mask><mask><mask>(<mask>,<mask>):\n",
      "    return<mask>*<mask>\n",
      "\n",
      "--------- PREDICTED -----------\n",
      "def __function(name, value):\n",
      "    return f*args\n",
      "\n",
      "--------- AST COMPARE -----------\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "import CodeCheckList.utils as utils\n",
    "\n",
    "prediction_number = 0\n",
    "print('------------- CODE -------------')\n",
    "print(code)\n",
    "print('\\n---------- MASKED -------------')\n",
    "print(masked_code)\n",
    "print('\\n--------- PREDICTED -----------')\n",
    "predicted_code = predictions[prediction_number]\n",
    "print(predicted_code)\n",
    "print('\\n--------- AST COMPARE -----------')\n",
    "filtered_nodes = []\n",
    "filtered_nodes_predict = []\n",
    "utils.find_nodes(bert_tokenizer.parser.parse(bytes(code, \"utf8\")).root_node, bert_tokenizer.node_types[bert_tokenizer.node_types.index(target_node_type)], filtered_nodes)\n",
    "utils.find_nodes(bert_tokenizer.parser.parse(bytes(predicted_code, \"utf8\")).root_node, bert_tokenizer.node_types[bert_tokenizer.node_types.index(target_node_type)], filtered_nodes_predict)\n",
    "print(len(filtered_nodes))\n",
    "print(len(filtered_nodes_predict))\n",
    "#base the evaluation on size comparison"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: code_search_net/all\n",
      "Found cached dataset code_search_net (/root/.cache/huggingface/datasets/code_search_net/all/1.0.0/8f2524e6b62f65af5f5d65c53715c654db7b08dc93e0b7bcce2ab2f286a75be1)\n",
      "Parameter 'function'=<function get_test_sets.<locals>.<lambda> at 0x7f09881c9430> of the transform datasets.arrow_dataset.Dataset.filter@2.0.1 couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e26aa1991d8497f8b01b295633fe228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/100529 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19408\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "from datasets import load_dataset \n",
    "import CodeCheckList.utils as utils\n",
    "import json\n",
    "\n",
    "\n",
    "evaluator = Evaluator(checkpoint, python_language)\n",
    "\n",
    "max_token_number = bert_tokenizer.tokenizer.max_len_single_sentence\n",
    "print(max_token_number)\n",
    "\n",
    "test_set = load_dataset(\"code_search_net\", split='test')\n",
    "test_set = utils.get_test_sets(test_set, python_language, max_token_number, bert_tokenizer)\n",
    "\n",
    "print(len(test_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def get_vid_from_url(url):\n",
      "        \"\"\"Extracts video ID from URL.\n",
      "        \"\"\"\n",
      "        return match1(url, r'youtu\\.be/([^?/]+)') or \\\n",
      "          match1(url, r'youtube\\.com/embed/([^/?]+)') or \\\n",
      "          match1(url, r'youtube\\.com/v/([^/?]+)') or \\\n",
      "          match1(url, r'youtube\\.com/watch/([^/?]+)') or \\\n",
      "          parse_query_param(url, 'v') or \\\n",
      "          parse_query_param(parse_query_param(url, 'u'), 'v')\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "print(test_set[0]['whole_func_string'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "### LOADING GALERAS\n",
    "test_set = json.load(open('/workspaces/CodeCheckList/semeru-datasets/galeras_curated_raw/airflow/data_1.json',))\n",
    "test_set += json.load(open('/workspaces/CodeCheckList/semeru-datasets/galeras_curated_raw/AliceMind-Baba/dataset17.json',))\n",
    "\n",
    "#test_set = json.load(open('/workspaces/CodeCheckList/semeru-datasets/galeras_previews_iteration_bk/combinedDataset/dataset.json',))\n",
    "#test_set += json.load(open('/workspaces/CodeCheckList/semeru-datasets/galeras_previews_iteration_bk/combinedDataset/dataset0.json',))\n",
    "#test_set += json.load(open('/workspaces/CodeCheckList/semeru-datasets/galeras_previews_iteration_bk/combinedDataset/dataset1.json',))\n",
    "\n",
    "test_set = utils.get_test_sets_galeras(test_set, python_language, max_token_number, bert_tokenizer)\n",
    "test_set = test_set[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Loading Model into GPU------------------\n",
      "-------- evaluating sample:0 --------\n",
      "-------- evaluating sample:1 --------\n",
      "-------- evaluating sample:2 --------\n",
      "-------- evaluating sample:3 --------\n",
      "-------- evaluating sample:4 --------\n",
      "-------- evaluating sample:5 --------\n",
      "-------- evaluating sample:6 --------\n",
      "-------- evaluating sample:7 --------\n",
      "-------- evaluating sample:8 --------\n",
      "-------- evaluating sample:9 --------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>ast_element</th>\n",
       "      <th>sample</th>\n",
       "      <th>masking_rate</th>\n",
       "      <th>numper_of_masked_tokens</th>\n",
       "      <th>ast_element_ocurrences</th>\n",
       "      <th>mask_jaccard</th>\n",
       "      <th>mask_sorensen_dice</th>\n",
       "      <th>mask_levenshtein</th>\n",
       "      <th>mask_random_avg_jaccard</th>\n",
       "      <th>...</th>\n",
       "      <th>mask_random_std_jaccard</th>\n",
       "      <th>mask_random_std_sorensen_dice</th>\n",
       "      <th>mask_random_std_levenshtein</th>\n",
       "      <th>n_ast_errors</th>\n",
       "      <th>ast_levels</th>\n",
       "      <th>n_whitespaces_</th>\n",
       "      <th>complexity</th>\n",
       "      <th>nloc</th>\n",
       "      <th>token_counts</th>\n",
       "      <th>n_ast_nodes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>comparison_operator</td>\n",
       "      <td>def test_should_generate_secret_with_specified...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.939262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056257</td>\n",
       "      <td>0.030556</td>\n",
       "      <td>0.049163</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>identifier</td>\n",
       "      <td>def test_should_generate_secret_with_specified...</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.834951</td>\n",
       "      <td>0.931147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069713</td>\n",
       "      <td>0.039115</td>\n",
       "      <td>0.053557</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>string</td>\n",
       "      <td>def test_should_generate_secret_with_specified...</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>11</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.391753</td>\n",
       "      <td>0.789183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071678</td>\n",
       "      <td>0.046481</td>\n",
       "      <td>0.087159</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>comparison_operator</td>\n",
       "      <td>def test_should_correctly_handle_password_with...</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.669261</td>\n",
       "      <td>0.512048</td>\n",
       "      <td>0.704585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184333</td>\n",
       "      <td>0.133976</td>\n",
       "      <td>0.192802</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>46</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>identifier</td>\n",
       "      <td>def test_should_correctly_handle_password_with...</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.973262</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.949499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052384</td>\n",
       "      <td>0.028038</td>\n",
       "      <td>0.037668</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>46</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>string</td>\n",
       "      <td>def test_should_correctly_handle_password_with...</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>11</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.351648</td>\n",
       "      <td>0.445253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201691</td>\n",
       "      <td>0.211770</td>\n",
       "      <td>0.205269</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>46</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>while_statement</td>\n",
       "      <td>def assert_tasks_on_executor(self, executor, t...</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0.825455</td>\n",
       "      <td>0.904382</td>\n",
       "      <td>0.832090</td>\n",
       "      <td>0.966440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023258</td>\n",
       "      <td>0.012153</td>\n",
       "      <td>0.019163</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>103</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>158</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>if_statement</td>\n",
       "      <td>def assert_tasks_on_executor(self, executor, t...</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0.860068</td>\n",
       "      <td>0.924771</td>\n",
       "      <td>0.880866</td>\n",
       "      <td>0.977678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043449</td>\n",
       "      <td>0.023696</td>\n",
       "      <td>0.036426</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>103</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>158</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>comparison_operator</td>\n",
       "      <td>def assert_tasks_on_executor(self, executor, t...</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>0.856115</td>\n",
       "      <td>0.922481</td>\n",
       "      <td>0.813433</td>\n",
       "      <td>0.988746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012353</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>0.009332</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>103</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>158</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>boolean_operator</td>\n",
       "      <td>def assert_tasks_on_executor(self, executor, t...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.918216</td>\n",
       "      <td>0.957364</td>\n",
       "      <td>0.917910</td>\n",
       "      <td>0.998517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004155</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>103</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>158</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>for_in_clause</td>\n",
       "      <td>def assert_tasks_on_executor(self, executor, t...</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.781690</td>\n",
       "      <td>0.877470</td>\n",
       "      <td>0.761194</td>\n",
       "      <td>0.983768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044704</td>\n",
       "      <td>0.024547</td>\n",
       "      <td>0.036090</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>103</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>158</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>if_clause</td>\n",
       "      <td>def assert_tasks_on_executor(self, executor, t...</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.925714</td>\n",
       "      <td>0.880597</td>\n",
       "      <td>0.997041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006727</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>103</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>158</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>identifier</td>\n",
       "      <td>def assert_tasks_on_executor(self, executor, t...</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>56</td>\n",
       "      <td>0.867314</td>\n",
       "      <td>0.928943</td>\n",
       "      <td>0.864078</td>\n",
       "      <td>0.895936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079423</td>\n",
       "      <td>0.045925</td>\n",
       "      <td>0.071027</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>103</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>158</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>string</td>\n",
       "      <td>def assert_tasks_on_executor(self, executor, t...</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>0.841379</td>\n",
       "      <td>0.913858</td>\n",
       "      <td>0.839552</td>\n",
       "      <td>0.993611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008706</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>0.006707</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>103</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>158</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>identifier</td>\n",
       "      <td>def test_tls(self):\\n        # These use test ...</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>22</td>\n",
       "      <td>0.849398</td>\n",
       "      <td>0.918567</td>\n",
       "      <td>0.849398</td>\n",
       "      <td>0.727859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174585</td>\n",
       "      <td>0.119040</td>\n",
       "      <td>0.188891</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>77</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>string</td>\n",
       "      <td>def test_tls(self):\\n        # These use test ...</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.695035</td>\n",
       "      <td>0.986065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015877</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>0.013277</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>77</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>identifier</td>\n",
       "      <td>def test_dask_executor_functions(self):\\n     ...</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.632681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113847</td>\n",
       "      <td>0.080435</td>\n",
       "      <td>0.140845</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>for_statement</td>\n",
       "      <td>def verify_provider_classes():\\n    \\n    with...</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0.840206</td>\n",
       "      <td>0.913165</td>\n",
       "      <td>0.844560</td>\n",
       "      <td>0.945029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048273</td>\n",
       "      <td>0.025864</td>\n",
       "      <td>0.043148</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>121</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>if_statement</td>\n",
       "      <td>def verify_provider_classes():\\n    \\n    with...</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.881443</td>\n",
       "      <td>0.936986</td>\n",
       "      <td>0.886010</td>\n",
       "      <td>0.985064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026945</td>\n",
       "      <td>0.013954</td>\n",
       "      <td>0.023974</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>121</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>identifier</td>\n",
       "      <td>def verify_provider_classes():\\n    \\n    with...</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>48</td>\n",
       "      <td>0.753968</td>\n",
       "      <td>0.859729</td>\n",
       "      <td>0.742972</td>\n",
       "      <td>0.712472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070043</td>\n",
       "      <td>0.049518</td>\n",
       "      <td>0.075783</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>121</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "      <td>string</td>\n",
       "      <td>def verify_provider_classes():\\n    \\n    with...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.949239</td>\n",
       "      <td>0.973958</td>\n",
       "      <td>0.963731</td>\n",
       "      <td>0.997293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010485</td>\n",
       "      <td>0.005351</td>\n",
       "      <td>0.006689</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>121</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6</td>\n",
       "      <td>comparison_operator</td>\n",
       "      <td>def test_python_callable_keyword_arguments_are...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.952727</td>\n",
       "      <td>0.975791</td>\n",
       "      <td>0.963235</td>\n",
       "      <td>0.992506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015885</td>\n",
       "      <td>0.008124</td>\n",
       "      <td>0.014885</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>164</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>identifier</td>\n",
       "      <td>def test_python_callable_keyword_arguments_are...</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>57</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.881119</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.870668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036286</td>\n",
       "      <td>0.020594</td>\n",
       "      <td>0.056115</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>164</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6</td>\n",
       "      <td>string</td>\n",
       "      <td>def test_python_callable_keyword_arguments_are...</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>6</td>\n",
       "      <td>0.797153</td>\n",
       "      <td>0.887129</td>\n",
       "      <td>0.801471</td>\n",
       "      <td>0.955289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020920</td>\n",
       "      <td>0.010956</td>\n",
       "      <td>0.024081</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>164</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7</td>\n",
       "      <td>return_statement</td>\n",
       "      <td>def get_conn(self) -&gt; Any:\\n        \\n        ...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.945205</td>\n",
       "      <td>0.970660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052381</td>\n",
       "      <td>0.028787</td>\n",
       "      <td>0.040462</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7</td>\n",
       "      <td>if_statement</td>\n",
       "      <td>def get_conn(self) -&gt; Any:\\n        \\n        ...</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0.516484</td>\n",
       "      <td>0.681159</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.647245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094003</td>\n",
       "      <td>0.066004</td>\n",
       "      <td>0.112841</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>identifier</td>\n",
       "      <td>def get_conn(self) -&gt; Any:\\n        \\n        ...</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>18</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.887324</td>\n",
       "      <td>0.792219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107683</td>\n",
       "      <td>0.066594</td>\n",
       "      <td>0.132468</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>string</td>\n",
       "      <td>def get_conn(self) -&gt; Any:\\n        \\n        ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.917808</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8</td>\n",
       "      <td>identifier</td>\n",
       "      <td>def setUp(self):\\n        with mock.patch(\\n  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>13</td>\n",
       "      <td>0.697368</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.589044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102809</td>\n",
       "      <td>0.078733</td>\n",
       "      <td>0.121362</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8</td>\n",
       "      <td>string</td>\n",
       "      <td>def setUp(self):\\n        with mock.patch(\\n  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.879310</td>\n",
       "      <td>0.935780</td>\n",
       "      <td>0.927273</td>\n",
       "      <td>0.730238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147318</td>\n",
       "      <td>0.099578</td>\n",
       "      <td>0.155656</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>9</td>\n",
       "      <td>identifier</td>\n",
       "      <td>def test_get_events(self, get_conn):\\n        ...</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>50</td>\n",
       "      <td>0.819005</td>\n",
       "      <td>0.900498</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.845264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090762</td>\n",
       "      <td>0.062313</td>\n",
       "      <td>0.112953</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>147</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>9</td>\n",
       "      <td>string</td>\n",
       "      <td>def test_get_events(self, get_conn):\\n        ...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.999386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002380</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>147</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sample_id          ast_element  \\\n",
       "0           0  comparison_operator   \n",
       "1           0           identifier   \n",
       "2           0               string   \n",
       "3           1  comparison_operator   \n",
       "4           1           identifier   \n",
       "5           1               string   \n",
       "6           2      while_statement   \n",
       "7           2         if_statement   \n",
       "8           2  comparison_operator   \n",
       "9           2     boolean_operator   \n",
       "10          2        for_in_clause   \n",
       "11          2            if_clause   \n",
       "12          2           identifier   \n",
       "13          2               string   \n",
       "14          3           identifier   \n",
       "15          3               string   \n",
       "16          4           identifier   \n",
       "17          5        for_statement   \n",
       "18          5         if_statement   \n",
       "19          5           identifier   \n",
       "20          5               string   \n",
       "21          6  comparison_operator   \n",
       "22          6           identifier   \n",
       "23          6               string   \n",
       "24          7     return_statement   \n",
       "25          7         if_statement   \n",
       "26          7           identifier   \n",
       "27          7               string   \n",
       "28          8           identifier   \n",
       "29          8               string   \n",
       "30          9           identifier   \n",
       "31          9               string   \n",
       "\n",
       "                                               sample  masking_rate  \\\n",
       "0   def test_should_generate_secret_with_specified...             1   \n",
       "1   def test_should_generate_secret_with_specified...             1   \n",
       "2   def test_should_generate_secret_with_specified...             1   \n",
       "3   def test_should_correctly_handle_password_with...             1   \n",
       "4   def test_should_correctly_handle_password_with...             1   \n",
       "5   def test_should_correctly_handle_password_with...             1   \n",
       "6   def assert_tasks_on_executor(self, executor, t...             1   \n",
       "7   def assert_tasks_on_executor(self, executor, t...             1   \n",
       "8   def assert_tasks_on_executor(self, executor, t...             1   \n",
       "9   def assert_tasks_on_executor(self, executor, t...             1   \n",
       "10  def assert_tasks_on_executor(self, executor, t...             1   \n",
       "11  def assert_tasks_on_executor(self, executor, t...             1   \n",
       "12  def assert_tasks_on_executor(self, executor, t...             1   \n",
       "13  def assert_tasks_on_executor(self, executor, t...             1   \n",
       "14  def test_tls(self):\\n        # These use test ...             1   \n",
       "15  def test_tls(self):\\n        # These use test ...             1   \n",
       "16  def test_dask_executor_functions(self):\\n     ...             1   \n",
       "17  def verify_provider_classes():\\n    \\n    with...             1   \n",
       "18  def verify_provider_classes():\\n    \\n    with...             1   \n",
       "19  def verify_provider_classes():\\n    \\n    with...             1   \n",
       "20  def verify_provider_classes():\\n    \\n    with...             1   \n",
       "21  def test_python_callable_keyword_arguments_are...             1   \n",
       "22  def test_python_callable_keyword_arguments_are...             1   \n",
       "23  def test_python_callable_keyword_arguments_are...             1   \n",
       "24  def get_conn(self) -> Any:\\n        \\n        ...             1   \n",
       "25  def get_conn(self) -> Any:\\n        \\n        ...             1   \n",
       "26  def get_conn(self) -> Any:\\n        \\n        ...             1   \n",
       "27  def get_conn(self) -> Any:\\n        \\n        ...             1   \n",
       "28  def setUp(self):\\n        with mock.patch(\\n  ...             1   \n",
       "29  def setUp(self):\\n        with mock.patch(\\n  ...             1   \n",
       "30  def test_get_events(self, get_conn):\\n        ...             1   \n",
       "31  def test_get_events(self, get_conn):\\n        ...             1   \n",
       "\n",
       "    numper_of_masked_tokens  ast_element_ocurrences  mask_jaccard  \\\n",
       "0                        20                       1      0.846154   \n",
       "1                        24                       9      0.818182   \n",
       "2                        52                      11      0.425000   \n",
       "3                        66                       1      0.502924   \n",
       "4                        24                       6      0.947917   \n",
       "5                       107                      11      0.318182   \n",
       "6                        60                       1      0.825455   \n",
       "7                        42                       1      0.860068   \n",
       "8                        33                       5      0.856115   \n",
       "9                        13                       1      0.918216   \n",
       "10                       22                       2      0.781690   \n",
       "11                       12                       2      0.861702   \n",
       "12                       90                      56      0.867314   \n",
       "13                       34                       6      0.841379   \n",
       "14                       48                      22      0.849398   \n",
       "15                       21                       7      0.638710   \n",
       "16                       33                      12      0.758621   \n",
       "17                       61                       1      0.840206   \n",
       "18                       30                       1      0.881443   \n",
       "19                      143                      48      0.753968   \n",
       "20                       15                       2      0.949239   \n",
       "21                        8                       1      0.952727   \n",
       "22                      143                      57      0.787500   \n",
       "23                       62                       6      0.797153   \n",
       "24                        4                       1      0.920000   \n",
       "25                       44                       1      0.516484   \n",
       "26                       32                      18      0.875000   \n",
       "27                        3                       1      0.917808   \n",
       "28                       42                      13      0.697368   \n",
       "29                       22                       1      0.879310   \n",
       "30                      121                      50      0.819005   \n",
       "31                       15                       4      0.875000   \n",
       "\n",
       "    mask_sorensen_dice  mask_levenshtein  mask_random_avg_jaccard  ...  \\\n",
       "0             0.916667          0.896907                 0.939262  ...   \n",
       "1             0.900000          0.834951                 0.931147  ...   \n",
       "2             0.596491          0.391753                 0.789183  ...   \n",
       "3             0.669261          0.512048                 0.704585  ...   \n",
       "4             0.973262          0.937500                 0.949499  ...   \n",
       "5             0.482759          0.351648                 0.445253  ...   \n",
       "6             0.904382          0.832090                 0.966440  ...   \n",
       "7             0.924771          0.880866                 0.977678  ...   \n",
       "8             0.922481          0.813433                 0.988746  ...   \n",
       "9             0.957364          0.917910                 0.998517  ...   \n",
       "10            0.877470          0.761194                 0.983768  ...   \n",
       "11            0.925714          0.880597                 0.997041  ...   \n",
       "12            0.928943          0.864078                 0.895936  ...   \n",
       "13            0.913858          0.839552                 0.993611  ...   \n",
       "14            0.918567          0.849398                 0.727859  ...   \n",
       "15            0.779528          0.695035                 0.986065  ...   \n",
       "16            0.862745          0.724138                 0.632681  ...   \n",
       "17            0.913165          0.844560                 0.945029  ...   \n",
       "18            0.936986          0.886010                 0.985064  ...   \n",
       "19            0.859729          0.742972                 0.712472  ...   \n",
       "20            0.973958          0.963731                 0.997293  ...   \n",
       "21            0.975791          0.963235                 0.992506  ...   \n",
       "22            0.881119          0.690000                 0.870668  ...   \n",
       "23            0.887129          0.801471                 0.955289  ...   \n",
       "24            0.958333          0.945205                 0.970660  ...   \n",
       "25            0.681159          0.464789                 0.647245  ...   \n",
       "26            0.933333          0.887324                 0.792219  ...   \n",
       "27            0.957143          0.943662                 1.000000  ...   \n",
       "28            0.821705          0.706667                 0.589044  ...   \n",
       "29            0.935780          0.927273                 0.730238  ...   \n",
       "30            0.900498          0.648148                 0.845264  ...   \n",
       "31            0.933333          0.898148                 0.999386  ...   \n",
       "\n",
       "    mask_random_std_jaccard  mask_random_std_sorensen_dice  \\\n",
       "0                  0.056257                       0.030556   \n",
       "1                  0.069713                       0.039115   \n",
       "2                  0.071678                       0.046481   \n",
       "3                  0.184333                       0.133976   \n",
       "4                  0.052384                       0.028038   \n",
       "5                  0.201691                       0.211770   \n",
       "6                  0.023258                       0.012153   \n",
       "7                  0.043449                       0.023696   \n",
       "8                  0.012353                       0.006276   \n",
       "9                  0.004155                       0.002092   \n",
       "10                 0.044704                       0.024547   \n",
       "11                 0.006727                       0.003396   \n",
       "12                 0.079423                       0.045925   \n",
       "13                 0.008706                       0.004405   \n",
       "14                 0.174585                       0.119040   \n",
       "15                 0.015877                       0.008168   \n",
       "16                 0.113847                       0.080435   \n",
       "17                 0.048273                       0.025864   \n",
       "18                 0.026945                       0.013954   \n",
       "19                 0.070043                       0.049518   \n",
       "20                 0.010485                       0.005351   \n",
       "21                 0.015885                       0.008124   \n",
       "22                 0.036286                       0.020594   \n",
       "23                 0.020920                       0.010956   \n",
       "24                 0.052381                       0.028787   \n",
       "25                 0.094003                       0.066004   \n",
       "26                 0.107683                       0.066594   \n",
       "27                 0.000000                       0.000000   \n",
       "28                 0.102809                       0.078733   \n",
       "29                 0.147318                       0.099578   \n",
       "30                 0.090762                       0.062313   \n",
       "31                 0.002380                       0.001195   \n",
       "\n",
       "    mask_random_std_levenshtein  n_ast_errors  ast_levels  n_whitespaces_  \\\n",
       "0                      0.049163             0          15              29   \n",
       "1                      0.053557             0          15              29   \n",
       "2                      0.087159             0          15              29   \n",
       "3                      0.192802             0          15              29   \n",
       "4                      0.037668             0          15              29   \n",
       "5                      0.205269             0          15              29   \n",
       "6                      0.019163             0          13             103   \n",
       "7                      0.036426             0          13             103   \n",
       "8                      0.009332             0          13             103   \n",
       "9                      0.002092             0          13             103   \n",
       "10                     0.036090             0          13             103   \n",
       "11                     0.004649             0          13             103   \n",
       "12                     0.071027             0          13             103   \n",
       "13                     0.006707             0          13             103   \n",
       "14                     0.188891             0          15              57   \n",
       "15                     0.013277             0          15              57   \n",
       "16                     0.140845             0          11               7   \n",
       "17                     0.043148             0          14              62   \n",
       "18                     0.023974             0          14              62   \n",
       "19                     0.075783             0          14              62   \n",
       "20                     0.006689             0          14              62   \n",
       "21                     0.014885             0          16             119   \n",
       "22                     0.056115             0          16             119   \n",
       "23                     0.024081             0          16             119   \n",
       "24                     0.040462             0          11              18   \n",
       "25                     0.112841             0          11              18   \n",
       "26                     0.132468             0          11              18   \n",
       "27                     0.000000             0          11              18   \n",
       "28                     0.121362             0          11              11   \n",
       "29                     0.155656             0          11              11   \n",
       "30                     0.112953             0          10              42   \n",
       "31                     0.001195             0          10              42   \n",
       "\n",
       "    complexity  nloc  token_counts  n_ast_nodes  \n",
       "0            1    15            50           96  \n",
       "1            1    15            50           96  \n",
       "2            1    15            50           96  \n",
       "3            1    17            46           90  \n",
       "4            1    17            46           90  \n",
       "5            1    17            46           90  \n",
       "6            8    17           158          267  \n",
       "7            8    17           158          267  \n",
       "8            8    17           158          267  \n",
       "9            8    17           158          267  \n",
       "10           8    17           158          267  \n",
       "11           8    17           158          267  \n",
       "12           8    17           158          267  \n",
       "13           8    17           158          267  \n",
       "14           1     9            77          140  \n",
       "15           1     9            77          140  \n",
       "16           1     3            27           43  \n",
       "17           3    22           121          196  \n",
       "18           3    22           121          196  \n",
       "19           3    22           121          196  \n",
       "20           3    22           121          196  \n",
       "21           1    32           164          275  \n",
       "22           1    32           164          275  \n",
       "23           1    32           164          275  \n",
       "24           2    11            45           74  \n",
       "25           2    11            45           74  \n",
       "26           2    11            45           74  \n",
       "27           2    11            45           74  \n",
       "28           1     6            32           53  \n",
       "29           1     6            32           53  \n",
       "30           1    26           147          215  \n",
       "31           1    26           147          215  \n",
       "\n",
       "[32 rows x 22 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "number_of_predictions = 3\n",
    "checkpoint = \"huggingface/CodeBERTa-small-v1\"\n",
    "python_language = \"python\"\n",
    "masking_rate = 1\n",
    "\n",
    "evaluator = Evaluator(checkpoint, python_language, gpu_available=True)\n",
    "\n",
    "#results_dataframe = evaluator(test_set, number_of_predictions, masking_rate)\n",
    "concepts = ['for_statement', 'while_statement', 'return_statement', 'if_statement', 'comparison_operator', 'boolean_operator', 'for_in_clause', 'if_clause', 'identifier' ,'string']\n",
    "results_dataframe = evaluator(test_set, concepts, masking_rate, 'code', 15)\n",
    "#results_dataframe = evaluator(test_set, bert_tokenizer.node_types, masking_rate, 'code')\n",
    "\n",
    "#results_dataframe.sort_values(by=['occurences'], ascending=False)\n",
    "\n",
    "results_dataframe\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5dfa21b9ea908da29bde2e75ccf59a8bff4851a5152f1f941db0158f4a372e7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
