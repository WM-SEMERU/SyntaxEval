{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import CodeCheckList\n",
    "import ast\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "from func_timeout import func_set_timeout, FunctionTimedOut\n",
    "from multiprocessing import Process, Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# From: https://github.com/github/CodeSearchNet/tree/master/function_parser\n",
    "def traverse(\n",
    "    node,       # tree-sitter node\n",
    "    results,    # list to append results to\n",
    ") -> None:\n",
    "    \"\"\"Traverse in a recursive way, a tree-sitter node and append results to a list.\"\"\"\n",
    "    if node.type == 'string':\n",
    "        results.append(node)\n",
    "        return\n",
    "    for n in node.children:\n",
    "        traverse(n, results)\n",
    "    if not node.children:\n",
    "        results.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def find_nodes(\n",
    "    node,               #Tree sitter ast treee\n",
    "    target_node_type,   #Target node type to search in the tree\n",
    "    results,            #List to append the resutls to\n",
    ") -> None: \n",
    "    \"\"\"Traverses the tree and find the specified node type\"\"\"\n",
    "    if node.type == target_node_type:\n",
    "        results.append(node)\n",
    "        return\n",
    "    for n in node.children:\n",
    "        find_nodes(n, target_node_type, results)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_node_type_list(\n",
    "    node\n",
    ") -> None:\n",
    "    \"\"\"Traverses the tree and get all the node types\"\"\"\n",
    "    node_types = []\n",
    "    def traverse_and_get_types(node, node_type_set):\n",
    "        node_type_set.append(node.type)\n",
    "        for n in node.children:\n",
    "            traverse_and_get_types(n, node_type_set)\n",
    "    traverse_and_get_types(node, node_types)\n",
    "    return node_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "#def calculate_tree_edit_distance(predicted_code_tree, source_code_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def unroll_node_types(\n",
    "    nested_node_types: dict, # node_types from tree-sitter\n",
    ") -> list: # list of node types\n",
    "    \"\"\"Unroll nested node types into a flat list of node types. This includes subtypes as well.\"\"\"\n",
    "    node_types = [node_type[\"type\"] for node_type in nested_node_types]\n",
    "    node_subtypes = [\n",
    "        node_subtype[\"type\"]\n",
    "        for node_type in nested_node_types\n",
    "        if \"subtypes\" in node_type\n",
    "        for node_subtype in node_type[\"subtypes\"]\n",
    "    ]\n",
    "    children_subtypes = [\n",
    "        children_type[\"type\"]\n",
    "        for node_type in nested_node_types\n",
    "        if \"children\" in node_type\n",
    "        for children_type in node_type[\"children\"][\"types\"]\n",
    "    ]\n",
    "    alias_subtypes = [\n",
    "        children_type[\"type\"]\n",
    "        for node_type in nested_node_types\n",
    "        if \"fields\" in node_type and \"alias\" in node_type[\"fields\"] \n",
    "        for children_type in node_type[\"fields\"][\"alias\"][\"types\"]\n",
    "    ]\n",
    "    return list(set(node_types + node_subtypes + children_subtypes + alias_subtypes + ['ERROR']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def convert_to_offset(\n",
    "    point,              #point to convert\n",
    "    lines: list         #list of lines in the source code\n",
    "    ):\n",
    "        \"\"\"Convert the point to an offset\"\"\"\n",
    "        row, column = point\n",
    "        chars_in_rows = sum(map(len, lines[:row])) + row\n",
    "        chars_in_columns = len(lines[row][:column])\n",
    "        offset = chars_in_rows + chars_in_columns\n",
    "        return offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_sub_set_test_set(test_set, test_size:int):\n",
    "    sub_samples = []\n",
    "    for sample in test_set:\n",
    "        sub_samples.append(sample)\n",
    "        if len(sub_samples)>=test_size:\n",
    "            break\n",
    "    return sub_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_random_sub_set_test_set(test_set, test_size:int):\n",
    "    sub_samples = []\n",
    "    while len(sub_samples)<test_size:\n",
    "        random_index = random.randrange(0,len(test_set))\n",
    "        sub_samples.append(test_set[random_index])\n",
    "    return sub_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def is_valid_code(code):\n",
    "    try:\n",
    "        ast.parse(code)\n",
    "    except:\n",
    "        return False\n",
    "    return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_balanced_snippet(snippet, threshold):\n",
    "    \"\"\"This method is used to prevent a kernel blocking when tree-sitter tries to parse a buggy snippet\"\"\"\n",
    "    proportion = len(re.findall(r\"([a-zA-Z0-9])\", snippet))/len(re.findall(r\"([^a-zA-Z0-9])\", snippet))\n",
    "    num_buggy_assigns = len(re.findall(r\"[^a-zA-Z0-9]+[=]+[^a-zA-Z0-9=]+[=]+[^a-zA-Z0-9=]+\", snippet))\n",
    "    num_buggy_tabs = len(re.findall(r\"\\n+[\\t]+[^a-zA-Z0-9\\t]+[\\t]+[^a-zA-Z0-9]+\", snippet))\n",
    "    num_buggy_spaces = len(re.findall(r\"\\n+[ ]+[^a-zA-Z0-9 ]+[ ]+[^a-zA-Z0-9]+\", snippet))\n",
    "    return proportion > threshold and num_buggy_assigns == 0 and num_buggy_tabs == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_test_sets(test_set, language, max_token_number, model_tokenizer, with_ranks=False, num_proc=1):\n",
    "    subset = test_set.filter(lambda sample: True if sample['language']== language \n",
    "            and len(sample['func_code_tokens']) < max_token_number\n",
    "            and len(model_tokenizer.tokenizer(sample['whole_func_string'])['input_ids']) < max_token_number\n",
    "            and is_balanced_snippet(sample['whole_func_string'], 1)\n",
    "            else False, num_proc=num_proc)\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def get_elements_by_percentage(elements, percentage):\n",
    "    indexes = set(random.sample(list(range(len(elements))), int(percentage*len(elements))))\n",
    "    return [n for i,n in enumerate(elements) if i in indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_parser_subprocess(code, parser):\n",
    "\n",
    "    def parse_code(queue, parser, code):\n",
    "        parser.parse(bytes(code, \"utf8\"))\n",
    "        queue.put('hi')\n",
    "    \n",
    "    @func_set_timeout(5)\n",
    "    def get_parser_result(queue):\n",
    "        return queue.get()\n",
    "    \n",
    "    queue = Queue()\n",
    "    parser_process = Process(target=parse_code, args=(queue, parser, code))\n",
    "    parser_process.start()\n",
    "    result = None\n",
    "\n",
    "    try:\n",
    "        result = get_parser_result(queue)\n",
    "    except FunctionTimedOut as e:\n",
    "        if parser_process.is_alive():\n",
    "            print('-parser deadlock-')\n",
    "            parser_process.kill()\n",
    "\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0,1,2,3,4,5,6,7,8,9]\n",
    "assert len(get_elements_by_percentage(a, 0)) == 0\n",
    "assert len(get_elements_by_percentage(a, 0.1)) == 1\n",
    "assert len(get_elements_by_percentage(a, 0.2)) == 2\n",
    "assert len(get_elements_by_percentage(a, 0.3)) == 3\n",
    "assert len(get_elements_by_percentage(a, 0.4)) == 4\n",
    "assert len(get_elements_by_percentage(a, 0.5)) == 5\n",
    "assert len(get_elements_by_percentage(a, 0.6)) == 6\n",
    "assert len(get_elements_by_percentage(a, 0.7)) == 7\n",
    "assert len(get_elements_by_percentage(a, 0.8)) == 8\n",
    "assert len(get_elements_by_percentage(a, 0.9)) == 9\n",
    "assert len(get_elements_by_percentage(a, 1)) == 10\n",
    "assert a == get_elements_by_percentage(a, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CodeCheckList.tokenizer import CodeTokenizer\n",
    "tokenizer = CodeTokenizer.from_pretrained(\"huggingface/CodeBERTa-small-v1\", \"python\")\n",
    "threshold = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'def scale(self, center=True, scale=True):\\n        \"\"\"\\nthe the\\n\\n\\n                                                                                                                                                          _\\n                     ____________=_=_===========________===______________________________==_____________________\\n_______\\n____\\n\\n___\\n\\n\\n\\n\\n\\n\\n\\n\\n        return return)'\n"
     ]
    }
   ],
   "source": [
    "code = \"def scale(self, center=True, scale=True):\\n        \\\"\\\"\\\"\\nthe the\\n\\n\\n                                                                                                                                                          _\\n                     ____________=_=_===========________===______________________________==_____________________\\n_______\\n____\\n\\n___\\n\\n\\n\\n\\n\\n\\n\\n\\n        return return)\"\n",
    "print(bytes(code, \"utf8\"))\n",
    "\n",
    "assert False == is_balanced_snippet(code, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"def m(a,b):\\n    r__urn a*b_________\"\n",
    "assert False == is_balanced_snippet(code, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "#code = \"def scale(self, center=True, scale=True):\\n        \\\"\\\"\\\"\\nthe the\\n\\n\\n                                                                                                                                                          _\\n                     ____________=_=_===========________===______________________________==_____________________\\n_______\\n____\\n\\n___\\n\\n\\n\\n\\n\\n\\n\\n\\n        return return)\"\n",
    "code = \"def m(a,b):\\n    r__urn a*b_________\"\n",
    "run_parser_subprocess(code, tokenizer.parser)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5dfa21b9ea908da29bde2e75ccf59a8bff4851a5152f1f941db0158f4a372e7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
