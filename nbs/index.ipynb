{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# SyntaxEval\n",
    "\n",
    "> Assessing Syntactic Capabilities of MLMs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Welcome, this is the repository that host the source code of **SyntaxEval** and results of our paper 'Which Syntactic Capabilities Are Statistically Learned by Masked Language Models for Code?'. \n",
    "\n",
    "Our work discusses the limitations of evaluating Masked Language Models (MLM) in code completion tasks. We highlight that relying on accuracy-based measurements may lead to an overestimation of models' capabilities by neglecting the syntax rules of Programming Languages. To address these issues, we introduce a technique called **SyntaxEval** in which **Syntactic Capabilities** are used to enhance the evaluation of MLMs. SyntaxEval automates the process of masking elements in the model input based on their Abstract Syntax Trees (ASTs). We conducted a case study on two popular MLMs using data from GitHub repositories. Our results showed negative causal effects between the node types and MLMs' accuracy. We conclude that MLMs under study fails to predict some syntactic capabilities."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use GPU to perform the predictions, please make sure to have pytorch correctly installed and GPU available to use. https://pytorch.org "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Dec 17 12:50:47 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.108.03   Driver Version: 510.108.03   CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A40          Off  | 00000000:01:00.0 Off |                    0 |\n",
      "|  0%   69C    P0   295W / 300W |  29143MiB / 46068MiB |     82%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A40          Off  | 00000000:25:00.0 Off |                    0 |\n",
      "|  0%   30C    P8    33W / 300W |     26MiB / 46068MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A40          Off  | 00000000:41:00.0 Off |                    0 |\n",
      "|  0%   30C    P8    35W / 300W |     26MiB / 46068MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A40          Off  | 00000000:61:00.0 Off |                    0 |\n",
      "|  0%   35C    P0    82W / 300W |     26MiB / 46068MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA A40          Off  | 00000000:81:00.0 Off |                    0 |\n",
      "|  0%   28C    P8    32W / 300W |     26MiB / 46068MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA A40          Off  | 00000000:A1:00.0 Off |                    0 |\n",
      "|  0%   58C    P0    90W / 300W |  42659MiB / 46068MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA A40          Off  | 00000000:C1:00.0 Off |                    0 |\n",
      "|  0%   62C    P0   296W / 300W |  42659MiB / 46068MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA A40          Off  | 00000000:E1:00.0 Off |                    0 |\n",
      "|  0%   67C    P0   321W / 300W |  42659MiB / 46068MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      3048      G   /usr/lib/xorg/Xorg                 23MiB |\n",
      "|    0   N/A  N/A   1807667      C   python3.8                       29117MiB |\n",
      "|    1   N/A  N/A      3048      G   /usr/lib/xorg/Xorg                 23MiB |\n",
      "|    2   N/A  N/A      3048      G   /usr/lib/xorg/Xorg                 23MiB |\n",
      "|    3   N/A  N/A      3048      G   /usr/lib/xorg/Xorg                 23MiB |\n",
      "|    4   N/A  N/A      3048      G   /usr/lib/xorg/Xorg                 23MiB |\n",
      "|    5   N/A  N/A      3048      G   /usr/lib/xorg/Xorg                 23MiB |\n",
      "|    5   N/A  N/A   2970647      C   julia                           42633MiB |\n",
      "|    6   N/A  N/A      3048      G   /usr/lib/xorg/Xorg                 23MiB |\n",
      "|    6   N/A  N/A   1778799      C   julia                           42633MiB |\n",
      "|    7   N/A  N/A      3048      G   /usr/lib/xorg/Xorg                 23MiB |\n",
      "|    7   N/A  N/A   1783425      C   julia                           42633MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a virtual environment, you can use conda, mamba or virtualenv. Then activate the envorinment and go to the project base path."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "mamba create code-check-list\n",
    "```\n",
    "```sh\n",
    "cd CodeCheckList\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, install CodeCheckList using the package manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "```sh\n",
    "pip install CodeCheckList\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Instructions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each module in CodeCheckList can be used independently, you can go to ./nbs if you want to look at more detail examples for each module.:\n",
    "\n",
    "| Module | Purpose |\n",
    "|--------|---------|\n",
    "|Checklist.Loader|Download and install Tree-sitter grammars|\n",
    "|Checklist.Tokenizer|Tokenize, Encode and Associate AST types, for  he requested source code snippet using the model's BPE and Tree-Sitter Parser|\n",
    "|Checklist.Masker|Mask the given source code snippet on occurrences for the requested AST element with a masking rate|\n",
    "|Checklist.Predictor|Attempts to predict the masked elements of a source code snippet using the selected model. Reports the results of top-k predictions|\n",
    "|Checklist.Judge|Compare the AST representations of original snippet and prediction to calculate similarity scores|\n",
    "|Checklist.Evaluator|Iterates over the specified number of samples from code-search-net, mask the ast elements defined by the programming language grammar in all the snippets, and report the results in a dataframe|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Evaluation pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Donwloading the grammar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First, download the grammar of the programming language of interest using the loader module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/svelascodimate/Documents/SEMERU/CodeCheckList/CodeCheckList/grammars\n"
     ]
    }
   ],
   "source": [
    "from CodeCheckList import loader\n",
    "\n",
    "python_language = \"python\"\n",
    "\n",
    "################ LOAD GRAMMAR\n",
    "languages = [python_language]\n",
    "loader.download_grammars(languages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Evaluator "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the evaluator Component to perform the evaluation of Linguistic Capabilities "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to setup first some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chechpoint to use\n",
    "checkpoint = \"huggingface/CodeBERTa-small-v1\"\n",
    "#number of sample sto evaluate\n",
    "number_of_samples = 5\n",
    "#masking rate to apply\n",
    "masking_rate = 25/100\n",
    "#top-k prediction per code sample\n",
    "number_of_predictions_per_sample = 3\n",
    "#if GPU:3 is available, set it to True, else False\n",
    "gpu_available = True\n",
    "#Save Path for the dataframe results\n",
    "save_path = \"output/CodeBERTa-small-v1/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, Instantiate the evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/svelascodimate/miniconda3/envs/code-check-list/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Loading Model into GPU------------------\n"
     ]
    }
   ],
   "source": [
    "from CodeCheckList.evaluator import Evaluator\n",
    "evaluator = Evaluator(checkpoint, python_language, gpu_available)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the samples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you need to define the source code samples to be used in the evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: code_search_net/all\n",
      "Found cached dataset code_search_net (/home/svelascodimate/.cache/huggingface/datasets/code_search_net/all/1.0.0/80a244ab541c6b2125350b764dc5c2b715f65f00de7a56107a28915fac173a27)\n",
      "Parameter 'function'=<function get_test_sets.<locals>.<lambda> at 0x7f6604bcb520> of the transform datasets.arrow_dataset.Dataset.filter@2.0.1 couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "  0%|          | 0/101 [00:00<?, ?ba/s]Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 101/101 [00:17<00:00,  5.71ba/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset \n",
    "import CodeCheckList.utils as utils\n",
    "\n",
    "test_set = utils.get_test_sets(load_dataset(\"code_search_net\", split='test'), python_language, evaluator.tokenizer.tokenizer.max_len_single_sentence, evaluator.tokenizer)\n",
    "test_set = utils.get_random_sub_set_test_set(test_set, number_of_samples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing the Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, call the evaluator to perform the evaluation of Linguistic Capabilities "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation will be conducted on each sample for each AST node type define din the grammar of the programming language.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['false', 'format_specifier', 'argument_list', 'augmented_assignment', 'exec_statement', 'true', 'exec', 'global', 'for_statement', 'for', '<<', '-=', 'module', '==', 'print', '//=', '[', 'else_clause', 'type', 'subscript', 'tuple_pattern', '<', 'match_statement', 'not_operator', '\"', 'float', 'dotted_name', 'or', 'finally', 'pair', 'try_statement', '/', 'set', 'concatenated_string', 'nonlocal', 'async', 'typed_parameter', 'wildcard_import', '>=', 'expression', 'yield', 'assignment', ')', '//', 'global_statement', 'class', '+', 'import_from_statement', 'not', 'parameters', '>>=', 'case_pattern', '^=', 'set_comprehension', '_simple_statement', '*=', 'relative_import', 'as_pattern', 'del', '}', 'conditional_expression', 'pass_statement', 'and', 'as', 'escape_sequence', 'chevron', 'pattern', 'future_import_statement', 'import_prefix', 'continue_statement', 'expression_list', 'list_splat_pattern', 'except_clause', 'if_clause', 'positional_separator', 'comparison_operator', 'return_statement', ':', '(', ',', 'typed_default_parameter', ']', '_compound_statement', 'list_splat', 'named_expression', 'parenthesized_expression', '+=', 'with', 'nonlocal_statement', 'case', 'ERROR', '<>', '|=', 'unary_operator', 'list_pattern', 'ellipsis', ':=', 'list', 'assert_statement', 'function_definition', 'continue', 'else', 'default_parameter', 'delete_statement', 'list_comprehension', 'dictionary', 'identifier', 'as_pattern_target', 'decorated_definition', 'comment', '__future__', 'def', '}}', 'aliased_import', 'match', '**=', '!=', 'class_definition', 'return', 'type_conversion', '{{', '.', '<=', 'generator_expression', '>', 'keyword_argument', 'import', 'from', '|', 'block', '<<=', 'case_clause', 'elif_clause', 'string', 'expression_statement', '@', 'for_in_clause', 'interpolation', '&=', '^', 'format_expression', '-', 'decorator', 'with_item', 'primary_expression', 'finally_clause', 'print_statement', 'if_statement', '>>', 'await', 'boolean_operator', 'binary_operator', 'raise_statement', 'try', '%=', 'keyword_separator', 'import_statement', 'parenthesized_list_splat', 'with_statement', 'with_clause', '**', '@=', '%', 'break_statement', 'dictionary_comprehension', 'slice', 'assert', 'break', '~', 'pass', 'dictionary_splat', 'none', 'in', 'attribute', 'call', 'lambda_parameters', 'elif', 'integer', 'dictionary_splat_pattern', ';', '*', 'tuple', '{', 'pattern_list', '/=', '->', 'raise', 'while_statement', 'parameter', '=', 'except', 'is', 'lambda', '&', 'if', 'while']\n"
     ]
    }
   ],
   "source": [
    "print(evaluator.tokenizer.node_types)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform the evaluation, simply call the evaluator with the defined parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- evaluating sample:0 --------\n",
      "-------- evaluating sample:1 --------\n",
      "-------- evaluating sample:2 --------\n",
      "-------- evaluating sample:3 --------\n",
      "-------- evaluating sample:4 --------\n"
     ]
    }
   ],
   "source": [
    "results_dataframe = evaluator(test_set, number_of_predictions_per_sample, masking_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are reported on a dataframe, that can be processed later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ast_element</th>\n",
       "      <th>occurences</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>sorensen_dice</th>\n",
       "      <th>levenshtein</th>\n",
       "      <th>jaccard_avg</th>\n",
       "      <th>sorensen_dice_avg</th>\n",
       "      <th>levenshtein_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>identifier</td>\n",
       "      <td>115</td>\n",
       "      <td>((0.9840425531914894, 1.0, 0.9692307692307692,...</td>\n",
       "      <td>((0.9919571045576407, 1.0, 0.984375, 1.0, 1.0)...</td>\n",
       "      <td>((0.9840425531914894, 1.0, 0.9692307692307692,...</td>\n",
       "      <td>(0.991, 0.961, 0.95)</td>\n",
       "      <td>(0.995, 0.98, 0.974)</td>\n",
       "      <td>(0.991, 0.955, 0.95)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>)</td>\n",
       "      <td>29</td>\n",
       "      <td>((1.0, 1.0, 1.0, 1.0, 1.0), (0.994623655913978...</td>\n",
       "      <td>((1.0, 1.0, 1.0, 1.0, 1.0), (0.997304582210242...</td>\n",
       "      <td>((1.0, 1.0, 1.0, 1.0, 1.0), (0.994623655913978...</td>\n",
       "      <td>(1.0, 0.992, 0.993)</td>\n",
       "      <td>(1.0, 0.996, 0.996)</td>\n",
       "      <td>(1.0, 0.995, 0.992)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>(</td>\n",
       "      <td>29</td>\n",
       "      <td>((1.0, 1.0, 1.0, 1.0, 1.0), (1.0, 1.0, 1.0, 1....</td>\n",
       "      <td>((1.0, 1.0, 1.0, 1.0, 1.0), (1.0, 1.0, 1.0, 1....</td>\n",
       "      <td>((1.0, 1.0, 1.0, 1.0, 1.0), (1.0, 1.0, 1.0, 1....</td>\n",
       "      <td>(1.0, 0.997, 0.987)</td>\n",
       "      <td>(1.0, 0.999, 0.993)</td>\n",
       "      <td>(1.0, 0.997, 0.99)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>.</td>\n",
       "      <td>28</td>\n",
       "      <td>((1.0, 1.0, 1.0, 1.0, 1.0), (1.0, 1.0, 1.0, 1....</td>\n",
       "      <td>((1.0, 1.0, 1.0, 1.0, 1.0), (1.0, 1.0, 1.0, 1....</td>\n",
       "      <td>((1.0, 1.0, 1.0, 1.0, 1.0), (1.0, 1.0, 1.0, 1....</td>\n",
       "      <td>(1.0, 0.996, 0.989)</td>\n",
       "      <td>(1.0, 0.998, 0.995)</td>\n",
       "      <td>(1.0, 0.996, 0.989)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\"</td>\n",
       "      <td>28</td>\n",
       "      <td>((1.0, 1.0, 1.0, 1.0, 1.0), (1.0, 1.0, 1.0, 1....</td>\n",
       "      <td>((1.0, 1.0, 1.0, 1.0, 1.0), (1.0, 1.0, 1.0, 1....</td>\n",
       "      <td>((1.0, 1.0, 1.0, 1.0, 1.0), (1.0, 1.0, 1.0, 1....</td>\n",
       "      <td>(1.0, 1.0, 1.0)</td>\n",
       "      <td>(1.0, 1.0, 1.0)</td>\n",
       "      <td>(1.0, 1.0, 1.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ast_element  occurences  \\\n",
       "106  identifier         115   \n",
       "42            )          29   \n",
       "78            (          29   \n",
       "121           .          28   \n",
       "24            \"          28   \n",
       "\n",
       "                                               jaccard  \\\n",
       "106  ((0.9840425531914894, 1.0, 0.9692307692307692,...   \n",
       "42   ((1.0, 1.0, 1.0, 1.0, 1.0), (0.994623655913978...   \n",
       "78   ((1.0, 1.0, 1.0, 1.0, 1.0), (1.0, 1.0, 1.0, 1....   \n",
       "121  ((1.0, 1.0, 1.0, 1.0, 1.0), (1.0, 1.0, 1.0, 1....   \n",
       "24   ((1.0, 1.0, 1.0, 1.0, 1.0), (1.0, 1.0, 1.0, 1....   \n",
       "\n",
       "                                         sorensen_dice  \\\n",
       "106  ((0.9919571045576407, 1.0, 0.984375, 1.0, 1.0)...   \n",
       "42   ((1.0, 1.0, 1.0, 1.0, 1.0), (0.997304582210242...   \n",
       "78   ((1.0, 1.0, 1.0, 1.0, 1.0), (1.0, 1.0, 1.0, 1....   \n",
       "121  ((1.0, 1.0, 1.0, 1.0, 1.0), (1.0, 1.0, 1.0, 1....   \n",
       "24   ((1.0, 1.0, 1.0, 1.0, 1.0), (1.0, 1.0, 1.0, 1....   \n",
       "\n",
       "                                           levenshtein           jaccard_avg  \\\n",
       "106  ((0.9840425531914894, 1.0, 0.9692307692307692,...  (0.991, 0.961, 0.95)   \n",
       "42   ((1.0, 1.0, 1.0, 1.0, 1.0), (0.994623655913978...   (1.0, 0.992, 0.993)   \n",
       "78   ((1.0, 1.0, 1.0, 1.0, 1.0), (1.0, 1.0, 1.0, 1....   (1.0, 0.997, 0.987)   \n",
       "121  ((1.0, 1.0, 1.0, 1.0, 1.0), (1.0, 1.0, 1.0, 1....   (1.0, 0.996, 0.989)   \n",
       "24   ((1.0, 1.0, 1.0, 1.0, 1.0), (1.0, 1.0, 1.0, 1....       (1.0, 1.0, 1.0)   \n",
       "\n",
       "        sorensen_dice_avg       levenshtein_avg  \n",
       "106  (0.995, 0.98, 0.974)  (0.991, 0.955, 0.95)  \n",
       "42    (1.0, 0.996, 0.996)   (1.0, 0.995, 0.992)  \n",
       "78    (1.0, 0.999, 0.993)    (1.0, 0.997, 0.99)  \n",
       "121   (1.0, 0.998, 0.995)   (1.0, 0.996, 0.989)  \n",
       "24        (1.0, 1.0, 1.0)       (1.0, 1.0, 1.0)  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dataframe = results_dataframe.sort_values(by=['occurences'], ascending=False)\n",
    "results_dataframe.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have the dataframe with the results of the evaluation, you can perform visualization tasks to analyse the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ast_element</th>\n",
       "      <th>occurences</th>\n",
       "      <th>jaccard_avg</th>\n",
       "      <th>sorensen_dice_avg</th>\n",
       "      <th>levenshtein_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>identifier</td>\n",
       "      <td>115</td>\n",
       "      <td>(0.991, 0.961, 0.95)</td>\n",
       "      <td>(0.995, 0.98, 0.974)</td>\n",
       "      <td>(0.991, 0.955, 0.95)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>)</td>\n",
       "      <td>29</td>\n",
       "      <td>(1.0, 0.992, 0.993)</td>\n",
       "      <td>(1.0, 0.996, 0.996)</td>\n",
       "      <td>(1.0, 0.995, 0.992)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>(</td>\n",
       "      <td>29</td>\n",
       "      <td>(1.0, 0.997, 0.987)</td>\n",
       "      <td>(1.0, 0.999, 0.993)</td>\n",
       "      <td>(1.0, 0.997, 0.99)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>.</td>\n",
       "      <td>28</td>\n",
       "      <td>(1.0, 0.996, 0.989)</td>\n",
       "      <td>(1.0, 0.998, 0.995)</td>\n",
       "      <td>(1.0, 0.996, 0.989)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\"</td>\n",
       "      <td>28</td>\n",
       "      <td>(1.0, 1.0, 1.0)</td>\n",
       "      <td>(1.0, 1.0, 1.0)</td>\n",
       "      <td>(1.0, 1.0, 1.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ast_element  occurences           jaccard_avg     sorensen_dice_avg  \\\n",
       "106  identifier         115  (0.991, 0.961, 0.95)  (0.995, 0.98, 0.974)   \n",
       "42            )          29   (1.0, 0.992, 0.993)   (1.0, 0.996, 0.996)   \n",
       "78            (          29   (1.0, 0.997, 0.987)   (1.0, 0.999, 0.993)   \n",
       "121           .          28   (1.0, 0.996, 0.989)   (1.0, 0.998, 0.995)   \n",
       "24            \"          28       (1.0, 1.0, 1.0)       (1.0, 1.0, 1.0)   \n",
       "\n",
       "          levenshtein_avg  \n",
       "106  (0.991, 0.955, 0.95)  \n",
       "42    (1.0, 0.995, 0.992)  \n",
       "78     (1.0, 0.997, 0.99)  \n",
       "121   (1.0, 0.996, 0.989)  \n",
       "24        (1.0, 1.0, 1.0)  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dataframe = results_dataframe.drop('jaccard',axis=1)\n",
    "results_dataframe = results_dataframe.drop('sorensen_dice',axis=1)\n",
    "results_dataframe = results_dataframe.drop('levenshtein',axis=1)\n",
    "results_dataframe.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can go to ./experimental_notebooks/result_visualizer.ipynb for a complete example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to **00_cda_evaluation.ipynb** to observe the results of the Confirmatory Data Analysis for Both Treatments in our evaluation: Masking Tokens Associated with AST node types and Random Masking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to **01_causal_evaluation.ipynb** To observe the results of our causal evaluation, where we compute correlations and also control for confounders. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "**experimental_data** folder contains the data that we used for our experiments. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "5dfa21b9ea908da29bde2e75ccf59a8bff4851a5152f1f941db0158f4a372e7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
