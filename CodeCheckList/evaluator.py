# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/evaluator.ipynb.

# %% auto 0
__all__ = ['Evaluator']

# %% ../nbs/evaluator.ipynb 2
import os
import pandas as pd

import CodeCheckList.utils as utils
from .tokenizer import CodeTokenizer
from .masker import Masker
from .predictor import Predictor
from .judge import Judge

import statistics
import textdistance

# %% ../nbs/evaluator.ipynb 4
class Evaluator:
    """Evaluator Module to perform all AST Evaluations"""
    def __init__(self, checkpoint: str, language, gpu_available=False):
        os.environ["TOKENIZERS_PARALLELISM"] = "true"
        self.tokenizer = CodeTokenizer.from_pretrained(checkpoint, language)
        self.masker = Masker(self.tokenizer)
        self.predictor = Predictor.from_pretrained(checkpoint, self.tokenizer, gpu_available)
        self.judge = Judge(self.tokenizer)

    def __call__(self, test_set, concepts: list, masking_rate: float, code_field: str):
        result_list = self.evaluate_concepts_in_test_set(concepts, test_set, masking_rate, code_field)
        results_dataframe = pd.DataFrame([], columns=[
            'sample_id', 'ast_element', 'sample', 'masking_rate', 
            'ast_element_ocurrences','mask_jaccard', 'mask_sorensen_dice', 'mask_levenshtein', 
            'mask_random_jaccard', 'mask_random_sorensen_dice', 'mask_random_levenshtein'
            ]) ## TODO ADD CONFOUNDERS
        for result_index, result in enumerate(result_list):
            results_dataframe.loc[len(results_dataframe.index)] = result
        return results_dataframe
    
    def pipeline(self, test_set, number_of_predictions: int, masking_rate: float):
        """Deprecated"""
        results_dict = self.evaluate_test_set(test_set, number_of_predictions, masking_rate)
        results_dataframe = pd.DataFrame([], columns=[
            'ast_element', 'occurences', 'jaccard', 'sorensen_dice', 'levenshtein', 'jaccard_avg', 'sorensen_dice_avg', 'levenshtein_avg'])
        for result_index, result in enumerate(results_dict):
            results_dataframe.loc[len(results_dataframe.index)] = [self.tokenizer.node_types[result_index], result[0], tuple(tuple(l) for l in result[1]), tuple(tuple(l) for l in result[2]), tuple(tuple(l) for l in result[3]), tuple(result[4]), tuple(result[5]), tuple(result[6])]
        return results_dataframe
    
    def evaluate_test_set(self, test_set, number_of_predictions: int, masking_rate: float):
        """Deprecated"""
        results_dict = []
        for node_type in self.tokenizer.node_types:
            results_dict.append([0,                                           #ocurrences
                                [[] for i in range(0,number_of_predictions)], #jaccard per prediction
                                [[] for i in range(0,number_of_predictions)], #sorensen_dice per prediction
                                [[] for i in range(0,number_of_predictions)], #levenshtein per prediction
                                [0 for i in range(0,number_of_predictions)],  #avg jaccard per prediction
                                [0 for i in range(0,number_of_predictions)],  #avg sorensen_dice per prediction
                                [0 for i in range(0,number_of_predictions)],  #avg levenshtein per prediction
                                ])
        for sample_index, sample in enumerate(test_set):
            print('-------- evaluating sample:'+str(sample_index)+' --------')
            for node_type_idx, node_type in enumerate(self.tokenizer.node_types):
                node_type_results = self.evaluate_node_type_on_snippet(sample['whole_func_string'], node_type_idx, number_of_predictions, masking_rate)
                if(len(node_type_results)>0):
                    results_dict[node_type_idx][0] += node_type_results[0][0]
                    for prediction_number_index in range(0, number_of_predictions):
                        if(node_type_results[prediction_number_index][1]!=None):
                            results_dict[node_type_idx][1][prediction_number_index].append(node_type_results[prediction_number_index][1])
                            results_dict[node_type_idx][4][prediction_number_index] = round(statistics.mean(results_dict[node_type_idx][1][prediction_number_index]),3)
                        if(node_type_results[prediction_number_index][2]!=None):
                            results_dict[node_type_idx][2][prediction_number_index].append(node_type_results[prediction_number_index][2])
                            results_dict[node_type_idx][5][prediction_number_index] = round(statistics.mean(results_dict[node_type_idx][2][prediction_number_index]),3)
                        if(node_type_results[prediction_number_index][3]!=None):
                            results_dict[node_type_idx][3][prediction_number_index].append(node_type_results[prediction_number_index][3])
                            results_dict[node_type_idx][6][prediction_number_index] = round(statistics.mean(results_dict[node_type_idx][3][prediction_number_index]),3)
        return results_dict
        
    def evaluate_node_type_on_snippet(self, source_code: str, target_node_type_idx: int, number_of_predictions: int, masking_rate: float):
        results=[]
        source_code_tree = self.tokenizer.parser.parse(bytes(source_code, "utf8"))
        source_code_nodes = []
        utils.find_nodes(source_code_tree.root_node, self.tokenizer.node_types[target_node_type_idx], source_code_nodes)
        if len(source_code_nodes) == 0:
            return results, 0
        masked_code_encoding, number_of_masked_tokens = self.masker.mask_ast_tokens(source_code, self.tokenizer(source_code), target_node_type_idx, masking_rate)
        if number_of_masked_tokens == 0: #Not masking anything
            return results, 0
        predictions = self.predictor(masked_code_encoding, self.tokenizer.tokenizer(source_code, return_tensors='pt'), number_of_predictions)  
        for prediction_number in range(0, number_of_predictions):
            predicted_code = predictions[prediction_number]
            prediction_results = self.judge(source_code, predicted_code)
            results.append([len(source_code_nodes), prediction_results[0], prediction_results[1], prediction_results[2]])
        return results, number_of_masked_tokens
    
    def evaluate_random_mask_on_snippet(self, source_code: str, number_of_predictions:int, number_tokens_to_mask: int):
        results=[]
        masked_code_encoding = self.masker.mask_random_tokens(self.tokenizer(source_code), number_tokens_to_mask)
        predictions = self.predictor(masked_code_encoding, self.tokenizer.tokenizer(source_code, return_tensors='pt'), number_of_predictions)
        for prediction_number in range(0, number_of_predictions):
            predicted_code = predictions[prediction_number]
            prediction_results = self.judge(source_code, predicted_code)
            results.append([0, prediction_results[0], prediction_results[1], prediction_results[2]])
        return results
    
    def evaluate_concepts_in_test_set(self, concepts: list, test_set, masking_rate: float, code_field: str):
        test_set_results = []
        for sample_index, sample in enumerate(test_set):
            print('-------- evaluating sample:'+str(sample_index)+' --------')
            for concept in concepts: 
                concept_mask_results, number_of_masked_tokens = self.evaluate_node_type_on_snippet(sample[code_field], self.tokenizer.node_types.index(concept), 1, masking_rate)
                random_mask_results = self.evaluate_random_mask_on_snippet(sample[code_field], 1, number_of_masked_tokens)
                if len(concept_mask_results)>0:
                    test_set_results.append([sample_index, concept, sample[code_field], masking_rate,
                                            concept_mask_results[0][0], concept_mask_results[0][1], concept_mask_results[0][2], concept_mask_results[0][3], 
                                            random_mask_results[0][1], random_mask_results[0][2], random_mask_results[0][3]]) #TODO ADD CONFOUNDERS
        return test_set_results

